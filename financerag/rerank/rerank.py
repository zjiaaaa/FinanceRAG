import json
import torch
import numpy as np
import csv
import gc
import sys
from pathlib import Path
from typing import List, Dict, Any
from sentence_transformers import CrossEncoder
from tqdm import tqdm
CURRENT_DIR = Path(__file__).resolve().parent
REPO_ROOT = CURRENT_DIR.parent.parent
if str(REPO_ROOT) not in sys.path:
    sys.path.append(str(REPO_ROOT))

from financerag.loader import load_all_tasks

TARGET_RETRIEVAL_MODEL = "BAAI/bge-m3"
TARGET_RETRIEVAL_DIRNAME = TARGET_RETRIEVAL_MODEL.replace("/", "__")

# ==========================================
# 1. Reranker é¡åˆ¥ (æ ¸å¿ƒæ¨¡å‹)
# ==========================================
class Reranker:
    def __init__(self, model_name: str, batch_size: int = 4):
        print(f" [Init] Loading Reranker model: {model_name} ...")
        
        device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"   Using device: {device}")
        
        # å¼·åˆ¶é–‹å•Ÿ fp16 åŠç²¾åº¦ä»¥ç¯€çœè¨˜æ†¶é«”
        self.model = CrossEncoder(
            model_name, 
            max_length=512, 
            device=device,
            trust_remote_code=True,
            automodel_args={"torch_dtype": torch.float16} 
        )
        self.batch_size = batch_size

    def rerank(self, query_text: str, candidates: List[Dict], corpus_data: Dict) -> List[Dict]:
        if not candidates:
            return []

        pairs = []
        valid_indices = []

        for i, doc_info in enumerate(candidates):
            doc_id = doc_info['doc_id']
            chunk_idx = doc_info['chunk_index']
            
            if doc_id not in corpus_data:
                continue 
            
            doc_obj = corpus_data[doc_id]

            # æå–æ¨™é¡Œèˆ‡å…§æ–‡
            title = str(doc_obj.get("title", "")).strip()
            content = ""
            
            if chunk_idx is not None and "chunks" in doc_obj and doc_obj["chunks"]:
                if 0 <= chunk_idx < len(doc_obj["chunks"]):
                    content = doc_obj["chunks"][chunk_idx]
                else:
                    content = doc_obj.get("text", "")
            else:
                content = doc_obj.get("text", "")

            # çµ„åˆ Title + Content
            if title:
                doc_text = f"{title}\n{content}"
            else:
                doc_text = content

            pairs.append([query_text, str(doc_text)])
            valid_indices.append(i)

        if not pairs:
            return []

        # é æ¸¬åˆ†æ•¸
        scores = self.model.predict(pairs, batch_size=self.batch_size, show_progress_bar=False)

        # æ›´æ–°åˆ†æ•¸
        reranked_results = []
        for j, list_idx in enumerate(valid_indices):
            original_doc = candidates[list_idx].copy()
            original_doc['rerank_score'] = float(scores[j])
            reranked_results.append(original_doc)

        # æ’åº
        reranked_results.sort(key=lambda x: x['rerank_score'], reverse=True)
        
        return reranked_results 

# ==========================================
# 2. è¼”åŠ©å·¥å…·ï¼šè½‰ Kaggle CSV
# ==========================================
def save_kaggle_submission(rerank_results: Dict, output_dir: Path):
    csv_path = output_dir / "submission.csv"
    with open(csv_path, "w", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        writer.writerow(["query_id", "corpus_id"])
        for qid, docs in rerank_results.items():
            for doc in docs:
                writer.writerow([qid, doc['doc_id']])
    print(f"   ğŸ† Kaggle submission generated: {csv_path.name}")

# ==========================================
# 3. [æ–°å¢] åŸ·è¡Œå–®ä¸€ä»»å‹™çš„å°è£å‡½å¼ (çµ¦ main.py å‘¼å«ç”¨)
# ==========================================
def run_reranking(
    task_obj: Any, 
    retrieval_results: Dict, 
    output_dir: Path, 
    top_k_rerank: int = 10,
    model_name: str = "BAAI/bge-reranker-base",
    pre_rerank_limit: int = 200,
) -> Dict:
    
    # 1. åˆå§‹åŒ–æ¨¡å‹ (æ¯æ¬¡å‘¼å«éƒ½é‡æ–°å»ºç«‹ï¼Œç¢ºä¿ä¹¾æ·¨)
    # batch_size è¨­ç‚º 2 æ¯”è¼ƒä¿éšª
    reranker = Reranker(model_name=model_name, batch_size = 4)
    
    final_output = {}
    print(f" Reranking {len(retrieval_results)} queries...")
    
    # 2. åŸ·è¡Œè¿´åœˆ
    for qid, docs in tqdm(retrieval_results.items(), desc="Reranking"):
        if qid in task_obj.queries:
            q_data = task_obj.queries[qid]
            query_text = q_data["text"] if isinstance(q_data, dict) else q_data

            # å…ˆæˆªæ–·å€™é¸ï¼Œé¿å…æµªè²» CrossEncoder è¨ˆç®—
            prefiltered_docs = docs[:pre_rerank_limit] if pre_rerank_limit else docs
            
            ranked_docs = reranker.rerank(query_text, prefiltered_docs, task_obj.corpus)
            final_output[qid] = ranked_docs[:top_k_rerank]

    # 3. å­˜æª” (JSON + CSV)
    save_path = output_dir / "rerank_results.json"
    with open(save_path, "w", encoding="utf-8") as f:
        json.dump(final_output, f, ensure_ascii=False, indent=2)
    
    save_kaggle_submission(final_output, output_dir)
    
    # 4. æ¸…ç†è¨˜æ†¶é«” (éå¸¸é‡è¦)
    del reranker
    torch.cuda.empty_cache()
    gc.collect()
    
    return final_output

# ==========================================
# 4. è¼”åŠ©ï¼šåˆä½µå¤šå€‹æª¢ç´¢çµæœ (å¤šæ¨¡å‹ä¸¦é›†)
# ==========================================
def merge_retrieval_results(retrieval_sets: List[Dict], pre_rerank_limit: int = 200) -> Dict:
    """
    å°‡ä¸åŒæª¢ç´¢æ¨¡å‹çš„çµæœåˆä½µï¼Œé‡å°åŒä¸€ doc/chunk ä¿ç•™æœ€é«˜åˆ†ï¼Œæœ€å¾Œæˆªæ–·è‡³ pre_rerank_limitã€‚
    """
    merged: Dict[str, Dict[Any, Dict]] = {}

    for retrieval_results in retrieval_sets:
        for qid, docs in retrieval_results.items():
            qslot = merged.setdefault(qid, {})
            for doc in docs:
                key = (doc.get("doc_id"), doc.get("chunk_index"))
                score = doc.get("score", doc.get("vector_score", 0.0))
                keep = qslot.get(key)
                if (keep is None) or (score > keep.get("score", 0.0)):
                    new_doc = doc.copy()
                    new_doc["score"] = score  # ç¢ºä¿å¾ŒçºŒæ’åºæœ‰å€¼
                    qslot[key] = new_doc

    trimmed: Dict[str, List[Dict]] = {}
    for qid, doc_map in merged.items():
        merged_list = sorted(doc_map.values(), key=lambda x: x.get("score", 0.0), reverse=True)
        trimmed[qid] = merged_list[:pre_rerank_limit] if pre_rerank_limit else merged_list
    return trimmed

# ==========================================
# 4. è‡ªå‹•æ‰¹æ¬¡åŸ·è¡Œé‚è¼¯ (å–®ç¨åŸ·è¡Œæ­¤æª”æ¡ˆæ™‚)
# ==========================================
if __name__ == "__main__":
    
    # --- å®šç¾©ä»»å‹™èˆ‡æ¨¡å‹å°æ‡‰è¡¨ ---
    MODEL_MAP = {
        "MultiHiertt": "jinaai/jina-reranker-v2-base-multilingual",
        "FinQABench": "jinaai/jina-reranker-v2-base-multilingual",
        "FinanceBench": "jinaai/jina-reranker-v2-base-multilingual",
        "FinQA": "Alibaba-NLP/gte-multilingual-reranker-base",
        "TATQA": "BAAI/bge-reranker-v2-m3",
        "ConvFinQA": "BAAI/bge-reranker-v2-m3",
        "FinDER": "BAAI/bge-reranker-v2-m3"
    }
    
    DEFAULT_MODEL = "BAAI/bge-reranker-base"

    print("\n=== [1/2] Scanning for Retrieval Results ===")
    root_dir_path = Path("dataset/embeddings")
    if not root_dir_path.exists():
        candidate = Path(__file__).resolve().parent.parent / root_dir_path
        if candidate.exists():
            root_dir_path = candidate

    all_json_files = list(root_dir_path.rglob("retrieval_results.json"))

    # ä¾ä»»å‹™èšåˆæ‰€æœ‰æ¨¡å‹çš„æª¢ç´¢çµæœ
    task_to_files: Dict[str, List[Path]] = {}
    for f in all_json_files:
        task_name = f.parent.parent.name
        task_to_files.setdefault(task_name, []).append(f)
      
    if not task_to_files:
        print(" æ‰¾ä¸åˆ°ä»»ä½• retrieval_results.jsonï¼Œè«‹å…ˆåŸ·è¡Œ Retrieval æ­¥é©Ÿï¼")
        exit()
        
    print(f"ğŸ” æ‰¾åˆ° {len(task_to_files)} å€‹ä»»å‹™å¾…è™•ç†ã€‚")

    print("\n=== [2/2] Start Batch Reranking ===")

    for task_name, files in task_to_files.items():
        # é¸æ“‡è¼¸å‡ºç›®éŒ„ï¼šå„ªå…ˆç”¨ BGE è·¯å¾‘ï¼Œå¦å‰‡å–ç¬¬ä¸€å€‹
        output_dir = None
        for f in files:
            if f.parent.name in {TARGET_RETRIEVAL_MODEL, TARGET_RETRIEVAL_DIRNAME}:
                output_dir = f.parent
                break
        if output_dir is None:
            output_dir = files[0].parent

        # æª¢æŸ¥æ˜¯å¦å·²å®Œæˆ (æœ‰ CSV å°±è·³é)
        # csv_output_path = output_dir / "submission.csv"
        # if csv_output_path.exists():
        #     print(f"â© [Skip] Task: {task_name} å·²ç¶“æœ‰ submission.csvï¼Œè·³éã€‚")
        #     continue 
        
        print(f"\nğŸš€ [Processing] Task: {task_name}")
        model_name = MODEL_MAP.get(task_name, DEFAULT_MODEL)
        
        try:
            # è¨˜æ†¶é«”å®‰å…¨è¼‰å…¥
            print("   â³ Loading dataset...")
            all_tasks = load_all_tasks()
            
            if task_name not in all_tasks:
                print(f"   âš ï¸ è·³éï¼šDataset ä¸­æ‰¾ä¸åˆ° {task_name}")
                del all_tasks
                gc.collect()
                continue
                
            task_obj = all_tasks[task_name]
            del all_tasks
            gc.collect()

            # è®€å–ä¸¦åˆä½µæ‰€æœ‰æ¨¡å‹çš„ Retrieval çµæœ
            retrieval_sets = []
            for json_file in files:
                with open(json_file, "r", encoding="utf-8") as f:
                    retrieval_sets.append(json.load(f))

            merged_retrieval = merge_retrieval_results(retrieval_sets, pre_rerank_limit=200)

            # ğŸ‘‡ ç›´æ¥å‘¼å«æˆ‘å€‘å‰›å‰›å¯«å¥½çš„ run_reranking å‡½å¼
            run_reranking(
                task_obj=task_obj,
                retrieval_results=merged_retrieval,
                output_dir=output_dir,
                top_k_rerank=10,
                model_name=model_name,
                pre_rerank_limit=200,
            )
            
            print(f"   âœ… Done: {task_name}")

            # é›™é‡æ¸…ç† (run_reranking è£¡é¢æ¸…éä¸€æ¬¡ï¼Œé€™è£¡å†æ¸…ä¸€æ¬¡ç¢ºä¿ task_obj ä¹Ÿæ¸…æ‰)
            del task_obj
            gc.collect()

        except Exception as e:
            print(f"   âŒ Error processing {task_name}: {e}")
            import traceback
            traceback.print_exc()

    print("\n=== ğŸ‰ All Reranking Tasks Completed! ===")
